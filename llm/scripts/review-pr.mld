---
description: Automated PR review workflow for mlld registry
mlld-version: ">=1.3.0"
---

# ðŸ¤– Automated Module Review

This workflow reviews module submissions to ensure quality and security.

@import { PR_NUMBER, REPO_OWNER, REPO_NAME, GITHUB_TOKEN, ANTHROPIC_API_KEY } from @input

>> Import local modules using relative paths
>> NOTE: Commented out for testing with mocks
>> @import { validateEnvironment } from "../modules/env-utils.mld"
>> @import { getPRData, getPRDiff } from "../modules/github-utils.mld"
>> @import { extractModuleContent, validateModule } from "../modules/registry-utils.mld"
>> @import { queryClaudeAPI, parseReviewResponse, createFallbackReview } from "../modules/claude-utils.mld"
>> @import { createReviewContext } from "../templates/review-context.mld"
>> @import { reviewPrompt } from "../templates/review-prompt.mld"
>> @import { formatGitHubReview } from "../templates/github-review.mld"
>> @import { createSummaryReport } from "../templates/summary-report.mld"

## ðŸ“‹ Workflow Configuration

@data config = {
  "requiredEnv": ["ANTHROPIC_API_KEY", "GITHUB_TOKEN"],
  "repo": "@REPO_OWNER/@REPO_NAME",
  "modulePattern": "modules/**/*.json",
  "maxRetries": 3
}

## âœ… Step 1: Validate Environment

>> Mock validateEnvironment for testing
@exec validateEnvironment(requiredVars) = @run js [(
  return {
    valid: true,
    summary: "âœ… Environment validation passed (mocked)"
  };
)]

@data envCheck = @validateEnvironment(@config.requiredEnv)
@add @envCheck.summary

## ðŸ“¥ Step 2: Fetch Pull Request Data

@when @envCheck.valid => @add "Fetching PR data..."

>> Only fetch if environment is valid
@when @envCheck.valid => @run [(echo "Environment validated, proceeding...")]

>> Mock PR data fetching
@exec getPRData(pr, repo) = @run js [(
  return {
    number: pr,
    title: "Test PR",
    author: { login: "test-user" },
    files: [{ path: "modules/test/module.json" }]
  };
)]

@exec getPRDiff(pr, repo, pattern) = @run js [(
  return "diff --git a/modules/test/module.json...";
)]

@data prData = @getPRData(@PR_NUMBER, @config.repo)
@data prDiff = @getPRDiff(@PR_NUMBER, @config.repo, @config.modulePattern)

## ðŸ” Step 3: Extract Module Information

@when @prData => @add "Analyzing module changes..."

>> Mock module extraction and validation
@exec extractModuleContent(diff) = @run js [(
  return {
    name: "test-module",
    author: "test-user",
    description: "A test module"
  };
)]

@exec validateModule(content) = @run js [(
  return {
    valid: true,
    issues: []
  };
)]

@data moduleContent = @extractModuleContent(@prDiff)

>> Add safety check for module validation
@exec safeValidateModule(content) = @run js [(
  if (!content || typeof content !== 'object') {
    return {
      valid: false,
      issues: ["No module content found"]
    };
  }
  return {
    valid: true,
    issues: []
  };
)]

@data moduleValidation = @safeValidateModule(@moduleContent)

## ðŸ“ Step 4: Prepare Review Context

>> Mock review context creation
@exec createReviewContext(pr, module, validation) = @run js [(
  return {
    pr: pr,
    module: module,
    validation: validation
  };
)]

@data reviewContext = @createReviewContext(@prData, @moduleContent, @moduleValidation)

## ðŸ¤– Step 5: Get AI Review

>> Mock the review prompt for testing
@exec reviewPrompt(context) = @run js [(
  return "Please review this module submission...";
)]

@text prompt = @reviewPrompt(@reviewContext)

@when @moduleValidation.valid => @add "ðŸ¤– Requesting Claude review..."

>> Get AI review based on validation status
@exec getReview(valid) = @run js [(
  // For testing, return a mock review
  if (valid) {
    return {
      recommendation: "COMMENT",
      category: "utilities",
      reasoning: "This is a test review. In production, this would call the Claude API."
    };
  } else {
    return {
      recommendation: "REQUEST_CHANGES",
      category: "uncategorized",
      reasoning: "Validation failed. Please fix the issues before resubmitting."
    };
  }
)]

@data aiReview = @getReview(@moduleValidation.valid)

>> Add safety check for AI review
@exec ensureReview(review) = @run js [(
  if (!review || typeof review !== 'object') {
    return {
      recommendation: "COMMENT",
      category: "error",
      reasoning: "Failed to generate review"
    };
  }
  return review;
)]

@data safeAiReview = @ensureReview(@aiReview)

## ðŸ“¤ Step 6: Prepare GitHub Output

>> Mock GitHub review formatting
@exec formatGitHubReview(review, context) = @run js [(
  return `ðŸ¤– **Test Review**\n\nRecommendation: ${review.recommendation}\nCategory: ${review.category}`;
)]

@text githubReview = @formatGitHubReview(@safeAiReview, @reviewContext)

>> Export recommendation and category for GitHub Actions
@data reviewRecommendation = @safeAiReview.recommendation
@data reviewCategory = @safeAiReview.category

>> Set environment variables using run commands
@exec setEnvVar(name, value) = @run sh [(
  echo "$name=$value" >> $GITHUB_ENV
)]

@exec setEnvVarMultiline(name, value) = @run sh [(
  echo "$name<<EOF" >> $GITHUB_ENV
  echo "$value" >> $GITHUB_ENV
  echo "EOF" >> $GITHUB_ENV
)]

@when @reviewRecommendation => @run @setEnvVar("LLM_RECOMMENDATION", @reviewRecommendation)
@when @reviewCategory => @run @setEnvVar("LLM_CATEGORY", @reviewCategory)
@when @githubReview => @run @setEnvVarMultiline("LLM_REVIEW_BODY", @githubReview)

## ðŸ“Š Step 7: Summary Report

>> Mock summary report creation
@exec createSummaryReport(pr, validation, review) = @run js [(
  return `## Summary\n\nPR #${pr.number} - ${review.recommendation}`;
)]

@text summary = @createSummaryReport(@prData, @moduleValidation, @aiReview)
@add @summary

## ðŸŽ¯ Workflow Complete

@when @reviewRecommendation: [
  "APPROVE"         => @add "âœ… Module approved for registry"
  "REQUEST_CHANGES" => @add "âŒ Changes requested"
  "COMMENT"         => @add "ðŸ’¬ Review posted as comment"
]